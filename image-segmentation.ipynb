{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nimport cv2\nimport pycocotools\nfrom pycocotools.coco import COCO\n\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"GPU Available: {torch.cuda.is_available()}\")\nprint(f\"GPU Name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-09T04:18:48.457782Z","iopub.execute_input":"2025-11-09T04:18:48.458380Z","iopub.status.idle":"2025-11-09T04:18:48.463864Z","shell.execute_reply.started":"2025-11-09T04:18:48.458359Z","shell.execute_reply":"2025-11-09T04:18:48.463100Z"}},"outputs":[{"name":"stdout","text":"PyTorch: 2.6.0+cu124\nGPU Available: True\nGPU Name: Tesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Clone the official Mask Scoring R-CNN repo\n!git clone https://github.com/zjhuang22/maskscoring_rcnn.git\n\n# Navigate into it\nimport os\nos.chdir('/kaggle/working/maskscoring_rcnn')\n\n# List contents to see what's available\nprint(\"\\nRepository contents:\")\n!ls -la\n\nprint(\"\\nLooking for key directories:\")\n!ls -d */ 2>/dev/null || echo \"No subdirectories found\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T04:18:48.464958Z","iopub.execute_input":"2025-11-09T04:18:48.465147Z","iopub.status.idle":"2025-11-09T04:18:49.992807Z","shell.execute_reply.started":"2025-11-09T04:18:48.465133Z","shell.execute_reply":"2025-11-09T04:18:49.992031Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'maskscoring_rcnn'...\nremote: Enumerating objects: 401, done.\u001b[K\nremote: Counting objects: 100% (77/77), done.\u001b[K\nremote: Compressing objects: 100% (29/29), done.\u001b[K\nremote: Total 401 (delta 51), reused 48 (delta 48), pack-reused 324 (from 1)\u001b[K\nReceiving objects: 100% (401/401), 5.21 MiB | 22.70 MiB/s, done.\nResolving deltas: 100% (129/129), done.\n\nRepository contents:\ntotal 60\ndrwxr-xr-x 11 root root 4096 Nov  9 04:18 .\ndrwxr-xr-x  4 root root 4096 Nov  9 02:54 ..\ndrwxr-xr-x  4 root root 4096 Nov  9 02:54 configs\ndrwxr-xr-x  2 root root 4096 Nov  9 02:54 demo\ndrwxr-xr-x  2 root root 4096 Nov  9 02:54 docker\ndrwxr-xr-x  8 root root 4096 Nov  9 02:54 .git\n-rw-r--r--  1 root root 1602 Nov  9 02:54 INSTALL.md\n-rw-r--r--  1 root root 1070 Nov  9 02:54 LICENSE\ndrwxr-xr-x 11 root root 4096 Nov  9 02:54 maskrcnn_benchmark\ndrwxr-xr-x  9 root root 4096 Nov  9 04:18 maskscoring_rcnn\n-rw-r--r--  1 root root 3950 Nov  9 02:54 README.md\ndrwxr-xr-x  2 root root 4096 Nov  9 03:39 results\n-rw-r--r--  1 root root 2105 Nov  9 02:54 setup.py\ndrwxr-xr-x  2 root root 4096 Nov  9 02:54 tests\ndrwxr-xr-x  2 root root 4096 Nov  9 02:54 tools\n\nLooking for key directories:\nconfigs/  docker/\t       maskscoring_rcnn/  tests/\ndemo/\t  maskrcnn_benchmark/  results/\t\t  tools/\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import os\nimport sys\n\nos.chdir('/kaggle/working/maskscoring_rcnn')\n\n# Add the repo to Python path instead of installing\nsys.path.insert(0, '/kaggle/working/maskscoring_rcnn')\n\nprint(\"‚úì Added MS R-CNN to Python path\")\nprint(f\"Python path: {sys.path[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T04:18:49.993765Z","iopub.execute_input":"2025-11-09T04:18:49.993967Z","iopub.status.idle":"2025-11-09T04:18:49.999436Z","shell.execute_reply.started":"2025-11-09T04:18:49.993946Z","shell.execute_reply":"2025-11-09T04:18:49.998669Z"}},"outputs":[{"name":"stdout","text":"‚úì Added MS R-CNN to Python path\nPython path: /kaggle/working/maskscoring_rcnn\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import os\nimport sys\n\nos.chdir('/kaggle/working/maskscoring_rcnn')\n\n# Add repo to Python path\nsys.path.insert(0, '/kaggle/working/maskscoring_rcnn')\n\n# Set environment variable\nos.environ['PYTHONPATH'] = '/kaggle/working/maskscoring_rcnn'\n\nprint(\"Testing direct imports without installation...\")\nprint(\"=\" * 60)\n\n# Try importing from the source directly\ntry:\n    import maskrcnn_benchmark\n    print(f\"‚úì maskrcnn_benchmark found at: {maskrcnn_benchmark.__file__}\")\nexcept ImportError:\n    print(\"‚úó Direct import failed, trying alternatives...\")\n\n# Check if files exist\nmaskrcnn_path = '/kaggle/working/maskscoring_rcnn/maskrcnn_benchmark'\nif os.path.exists(maskrcnn_path):\n    print(f\"‚úì maskrcnn_benchmark directory exists\")\n    init_file = os.path.join(maskrcnn_path, '__init__.py')\n    if os.path.exists(init_file):\n        print(f\"‚úì __init__.py found\")\n    else:\n        print(\"‚úó __init__.py missing - creating it...\")\n        # Create missing __init__.py if needed\n        with open(init_file, 'w') as f:\n            f.write(\"# Mask R-CNN Benchmark\\n\")\nelse:\n    print(\"‚úó maskrcnn_benchmark directory not found!\")\n\nprint(\"\\n‚úì Setup complete\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T04:18:50.000974Z","iopub.execute_input":"2025-11-09T04:18:50.001167Z","iopub.status.idle":"2025-11-09T04:18:50.015537Z","shell.execute_reply.started":"2025-11-09T04:18:50.001153Z","shell.execute_reply":"2025-11-09T04:18:50.014758Z"}},"outputs":[{"name":"stdout","text":"Testing direct imports without installation...\n============================================================\n‚úì maskrcnn_benchmark found at: /kaggle/working/maskscoring_rcnn/maskrcnn_benchmark/__init__.py\n‚úì maskrcnn_benchmark directory exists\n‚úì __init__.py found\n\n‚úì Setup complete\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Just install the dependencies, not the package itself\n!pip install -q yacs\n!pip install -q tensorboard\n\nprint(\"‚úì Dependencies installed\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T04:18:50.016117Z","iopub.execute_input":"2025-11-09T04:18:50.016350Z","iopub.status.idle":"2025-11-09T04:18:57.327502Z","shell.execute_reply.started":"2025-11-09T04:18:50.016326Z","shell.execute_reply":"2025-11-09T04:18:57.326547Z"}},"outputs":[{"name":"stdout","text":"‚úì Dependencies installed\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import os\nos.chdir('/kaggle/working/maskscoring_rcnn')\n\n# Check if test script exists\ntest_script = 'tools/test_net.py'\nif os.path.exists(test_script):\n    print(f\"‚úì Found: {test_script}\")\n    \n    # Read first few lines to understand structure\n    with open(test_script, 'r') as f:\n        lines = f.readlines()[:20]\n        print(\"\\nFirst 20 lines of test_net.py:\")\n        print(\"=\" * 60)\n        for i, line in enumerate(lines, 1):\n            print(f\"{i:2d}: {line.rstrip()}\")\nelse:\n    print(f\"‚úó {test_script} not found\")\n    \n# List all tools\nprint(\"\\n\\nAvailable scripts in tools/:\")\n!ls -lh tools/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T04:18:57.328809Z","iopub.execute_input":"2025-11-09T04:18:57.329056Z","iopub.status.idle":"2025-11-09T04:18:57.495980Z","shell.execute_reply.started":"2025-11-09T04:18:57.329030Z","shell.execute_reply":"2025-11-09T04:18:57.495310Z"}},"outputs":[{"name":"stdout","text":"‚úì Found: tools/test_net.py\n\nFirst 20 lines of test_net.py:\n============================================================\n 1: # Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n 2: # Set up custom environment before nearly anything else is imported\n 3: # NOTE: this should be the first import (no not reorder)\n 4: from maskrcnn_benchmark.utils.env import setup_environment  # noqa F401 isort:skip\n 5: \n 6: import argparse\n 7: import os\n 8: \n 9: import torch\n10: from maskrcnn_benchmark.config import cfg\n11: from maskrcnn_benchmark.data import make_data_loader\n12: from maskrcnn_benchmark.engine.inference import inference\n13: from maskrcnn_benchmark.modeling.detector import build_detection_model\n14: from maskrcnn_benchmark.utils.checkpoint import DetectronCheckpointer\n15: from maskrcnn_benchmark.utils.collect_env import collect_env_info\n16: from maskrcnn_benchmark.utils.comm import synchronize, get_rank\n17: from maskrcnn_benchmark.utils.logger import setup_logger\n18: from maskrcnn_benchmark.utils.miscellaneous import mkdir\n19: \n20: \n\n\nAvailable scripts in tools/:\ntotal 12K\n-rw-r--r-- 1 root root 3.4K Nov  9 02:54 test_net.py\n-rw-r--r-- 1 root root 5.3K Nov  9 02:54 train_net.py\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import os\nimport sys\n\nos.chdir('/kaggle/working/maskscoring_rcnn')\n\n# Create a compatibility module for torch._six\ncompat_code = '''\n\"\"\"PyTorch 2.x compatibility shim\"\"\"\nimport sys\nimport torch\n\n# PyTorch 2.x removed torch._six, so we create a replacement\nif not hasattr(torch, '_six'):\n    class _six:\n        string_classes = (str,)\n        \n        @staticmethod\n        def string_types(*args):\n            return str\n    \n    torch._six = _six\n\nprint(\"‚úì PyTorch compatibility shim loaded\")\n'''\n\n# Create compat module\ncompat_path = 'maskrcnn_benchmark/torch_compat.py'\nwith open(compat_path, 'w') as f:\n    f.write(compat_code)\n\nprint(f\"‚úì Created compatibility module at {compat_path}\")\n\n# Update __init__.py to import compat first\ninit_path = 'maskrcnn_benchmark/__init__.py'\nwith open(init_path, 'r') as f:\n    init_content = f.read()\n\n# Add compat import at the very beginning if not already there\nif 'torch_compat' not in init_content:\n    init_content = 'from . import torch_compat\\n' + init_content\n    with open(init_path, 'w') as f:\n        f.write(init_content)\n    print(f\"‚úì Updated {init_path} with compat import\")\nelse:\n    print(f\"‚úì torch_compat already imported in {init_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T04:18:57.497092Z","iopub.execute_input":"2025-11-09T04:18:57.497360Z","iopub.status.idle":"2025-11-09T04:18:57.504439Z","shell.execute_reply.started":"2025-11-09T04:18:57.497336Z","shell.execute_reply":"2025-11-09T04:18:57.503821Z"}},"outputs":[{"name":"stdout","text":"‚úì Created compatibility module at maskrcnn_benchmark/torch_compat.py\n‚úì Updated maskrcnn_benchmark/__init__.py with compat import\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import os\n\nprint(\"Checking available COCO dataset paths on Kaggle...\")\nprint(\"=\" * 60)\n\n# Check what's available in /kaggle/input\nkaggle_input = '/kaggle/input'\nprint(f\"\\nContents of {kaggle_input}:\")\nfor item in os.listdir(kaggle_input):\n    path = os.path.join(kaggle_input, item)\n    if os.path.isdir(path):\n        print(f\"  üìÅ {item}\")\n\n# Look for COCO specifically\nprint(\"\\nSearching for COCO dataset...\")\nfor item in os.listdir(kaggle_input):\n    if 'coco' in item.lower():\n        coco_path = os.path.join(kaggle_input, item)\n        print(f\"\\n‚úì Found: {coco_path}\")\n        \n        # Check contents\n        try:\n            contents = os.listdir(coco_path)\n            print(f\"  Contents: {contents[:5]}...\")  # First 5 items\n            \n            # Check for annotations\n            if 'annotations' in contents:\n                ann_path = os.path.join(coco_path, 'annotations')\n                anns = os.listdir(ann_path)\n                print(f\"  Annotations: {anns[:3]}\")\n        except:\n            pass\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T04:18:57.505108Z","iopub.execute_input":"2025-11-09T04:18:57.505292Z","iopub.status.idle":"2025-11-09T04:18:57.524300Z","shell.execute_reply.started":"2025-11-09T04:18:57.505256Z","shell.execute_reply":"2025-11-09T04:18:57.523695Z"}},"outputs":[{"name":"stdout","text":"Checking available COCO dataset paths on Kaggle...\n============================================================\n\nContents of /kaggle/input:\n  üìÅ coco-2017-dataset\n\nSearching for COCO dataset...\n\n‚úì Found: /kaggle/input/coco-2017-dataset\n  Contents: ['coco2017']...\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import os\n\ncoco_path = '/kaggle/input/coco-2017-dataset/coco2017'\n\nprint(\"Checking COCO2017 structure...\")\nprint(\"=\" * 60)\n\nif os.path.exists(coco_path):\n    contents = os.listdir(coco_path)\n    print(f\"\\nContents of {coco_path}:\")\n    for item in contents:\n        item_path = os.path.join(coco_path, item)\n        if os.path.isdir(item_path):\n            count = len(os.listdir(item_path))\n            print(f\"  üìÅ {item}: {count} items\")\n        else:\n            size = os.path.getsize(item_path) / (1024**2)\n            print(f\"  üìÑ {item}: {size:.1f} MB\")\nelse:\n    print(f\"‚úó Path not found: {coco_path}\")\n    \n    # Check parent\n    parent = '/kaggle/input/coco-2017-dataset'\n    print(f\"\\nTrying parent: {parent}\")\n    if os.path.exists(parent):\n        print(f\"Contents:\")\n        for item in os.listdir(parent):\n            print(f\"  - {item}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T04:18:57.526564Z","iopub.execute_input":"2025-11-09T04:18:57.526762Z","iopub.status.idle":"2025-11-09T04:19:02.528561Z","shell.execute_reply.started":"2025-11-09T04:18:57.526747Z","shell.execute_reply":"2025-11-09T04:19:02.527720Z"}},"outputs":[{"name":"stdout","text":"Checking COCO2017 structure...\n============================================================\n\nContents of /kaggle/input/coco-2017-dataset/coco2017:\n  üìÅ val2017: 5000 items\n  üìÅ annotations: 6 items\n  üìÅ test2017: 40670 items\n  üìÅ train2017: 118287 items\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import os\nimport sys\nimport torch\nimport cv2\nimport numpy as np\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\nfrom torchvision.models.detection import maskrcnn_resnet50_fpn\nimport json\nimport time\n\nos.chdir('/kaggle/working/maskscoring_rcnn')\nsys.path.insert(0, '/kaggle/working/maskscoring_rcnn')\n\nprint(\"=\" * 60)\nprint(\"MS R-CNN BASELINE - TORCHVISION\")\nprint(\"=\" * 60)\n\n# Correct paths\ncoco_ann_file = '/kaggle/input/coco-2017-dataset/coco2017/annotations/instances_val2017.json'\ncoco_images_dir = '/kaggle/input/coco-2017-dataset/coco2017/val2017'\n\nprint(f\"\\n‚úì COCO annotations: {coco_ann_file}\")\nprint(f\"‚úì COCO images: {coco_images_dir}\")\n\n# Load COCO\nprint(\"\\nLoading COCO validation set...\")\ncoco_gt = COCO(coco_ann_file)\nimg_ids = sorted(coco_gt.getImgIds())\nprint(f\"‚úì Loaded {len(img_ids)} images\")\n\n# Load model\nprint(\"\\nLoading Mask R-CNN (ResNet-50-FPN)...\")\nmodel = maskrcnn_resnet50_fpn(pretrained=True)\nmodel.eval()\nmodel.cuda()\nprint(\"‚úì Model loaded and moved to GPU\")\n\n# Inference\nprint(f\"\\nRunning inference on validation set...\")\nprint(\"=\" * 60)\n\npredictions = []\ntimes = []\nprocessed = 0\n\nfor idx, img_id in enumerate(img_ids):\n    img_info = coco_gt.loadImgs(img_id)[0]\n    img_path = os.path.join(coco_images_dir, img_info['file_name'])\n    \n    if not os.path.exists(img_path):\n        continue\n    \n    # Load image\n    img = cv2.imread(img_path)\n    if img is None:\n        continue\n        \n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img_tensor = torch.from_numpy(img_rgb).float().cuda() / 255.0\n    img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0)\n    \n    # Inference\n    start = time.time()\n    with torch.no_grad():\n        outputs = model([img_tensor.squeeze(0)])\n    times.append(time.time() - start)\n    \n    # Extract predictions\n    boxes = outputs[0]['boxes'].cpu().numpy()\n    scores = outputs[0]['scores'].cpu().numpy()\n    labels = outputs[0]['labels'].cpu().numpy()\n    \n    # Convert to COCO format\n    for i in range(len(boxes)):\n        x1, y1, x2, y2 = boxes[i]\n        \n        predictions.append({\n            'image_id': int(img_id),\n            'category_id': int(labels[i]),\n            'bbox': [float(x1), float(y1), float(x2-x1), float(y2-y1)],\n            'score': float(scores[i])\n        })\n    \n    processed += 1\n    \n    if (processed) % 500 == 0:\n        avg_time = np.mean(times[-500:])\n        remaining = len(img_ids) - processed\n        eta_secs = remaining * avg_time\n        print(f\"  {processed}/{len(img_ids)} - {avg_time:.3f}s/img - ETA: {eta_secs/60:.1f} mins\")\n\nprint(f\"\\n\" + \"=\" * 60)\nprint(f\"‚úì Inference complete!\")\nprint(f\"‚úì Processed: {processed} images\")\nprint(f\"‚úì Total predictions: {len(predictions)}\")\nprint(f\"‚úì Average time: {np.mean(times):.3f}s per image\")\nprint(f\"‚úì Throughput: {1/np.mean(times):.2f} FPS\")\n\n# Save predictions\nos.makedirs('results', exist_ok=True)\npred_file = 'results/predictions.json'\nwith open(pred_file, 'w') as f:\n    json.dump(predictions, f)\nprint(f\"\\n‚úì Predictions saved to: {pred_file}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T04:19:02.529499Z","iopub.execute_input":"2025-11-09T04:19:02.529792Z","iopub.status.idle":"2025-11-09T04:26:53.376021Z","shell.execute_reply.started":"2025-11-09T04:19:02.529768Z","shell.execute_reply":"2025-11-09T04:26:53.375186Z"}},"outputs":[{"name":"stdout","text":"============================================================\nMS R-CNN BASELINE - TORCHVISION\n============================================================\n\n‚úì COCO annotations: /kaggle/input/coco-2017-dataset/coco2017/annotations/instances_val2017.json\n‚úì COCO images: /kaggle/input/coco-2017-dataset/coco2017/val2017\n\nLoading COCO validation set...\nloading annotations into memory...\nDone (t=0.46s)\ncreating index...\nindex created!\n‚úì Loaded 5000 images\n\nLoading Mask R-CNN (ResNet-50-FPN)...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 170M/170M [00:00<00:00, 215MB/s] \n","output_type":"stream"},{"name":"stdout","text":"‚úì Model loaded and moved to GPU\n\nRunning inference on validation set...\n============================================================\n  500/5000 - 0.083s/img - ETA: 6.2 mins\n  1000/5000 - 0.085s/img - ETA: 5.7 mins\n  1500/5000 - 0.084s/img - ETA: 4.9 mins\n  2000/5000 - 0.083s/img - ETA: 4.1 mins\n  2500/5000 - 0.083s/img - ETA: 3.5 mins\n  3000/5000 - 0.084s/img - ETA: 2.8 mins\n  3500/5000 - 0.084s/img - ETA: 2.1 mins\n  4000/5000 - 0.083s/img - ETA: 1.4 mins\n  4500/5000 - 0.084s/img - ETA: 0.7 mins\n  5000/5000 - 0.083s/img - ETA: 0.0 mins\n\n============================================================\n‚úì Inference complete!\n‚úì Processed: 5000 images\n‚úì Total predictions: 170603\n‚úì Average time: 0.083s per image\n‚úì Throughput: 11.98 FPS\n\n‚úì Predictions saved to: results/predictions.json\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import os\nimport json\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\n\nos.chdir('/kaggle/working/maskscoring_rcnn')\n\nprint(\"=\" * 60)\nprint(\"EVALUATING BASELINE RESULTS\")\nprint(\"=\" * 60)\n\n# Load ground truth\ncoco_ann_file = '/kaggle/input/coco-2017-dataset/coco2017/annotations/instances_val2017.json'\ncoco_gt = COCO(coco_ann_file)\n\n# Load predictions\nprint(\"\\nLoading predictions...\")\npred_file = 'results/predictions.json'\ncoco_dt = coco_gt.loadRes(pred_file)\n\n# Evaluate\nprint(\"Computing COCO metrics (this may take a few minutes)...\")\ncoco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\ncoco_eval.evaluate()\ncoco_eval.accumulate()\ncoco_eval.summarize()\n\n# Extract results\nap_50_95 = coco_eval.stats[0]\nap_50 = coco_eval.stats[1]\nap_75 = coco_eval.stats[2]\nap_small = coco_eval.stats[3]\nap_medium = coco_eval.stats[4]\nap_large = coco_eval.stats[5]\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"BASELINE RESULTS SUMMARY\")\nprint(\"=\" * 60)\nprint(f\"\\nModel: Mask R-CNN (ResNet-50-FPN)\")\nprint(f\"Framework: Torchvision Pretrained\")\nprint(f\"Dataset: COCO 2017 Validation ({len(coco_gt.getImgIds())} images)\")\nprint(f\"\\nBounding Box Metrics:\")\nprint(f\"  AP@IoU=0.50:0.95: {ap_50_95:.4f}\")\nprint(f\"  AP@IoU=0.50:     {ap_50:.4f}\")\nprint(f\"  AP@IoU=0.75:     {ap_75:.4f}\")\nprint(f\"  AP_small:        {ap_small:.4f}\")\nprint(f\"  AP_medium:       {ap_medium:.4f}\")\nprint(f\"  AP_large:        {ap_large:.4f}\")\n\n# Save results\nbaseline_results = {\n    'model': 'Mask R-CNN (ResNet-50-FPN)',\n    'framework': 'Torchvision',\n    'dataset': 'COCO 2017 Validation',\n    'num_images': len(coco_gt.getImgIds()),\n    'num_predictions': len(json.load(open(pred_file))),\n    'metrics': {\n        'AP@0.50:0.95': float(ap_50_95),\n        'AP@0.50': float(ap_50),\n        'AP@0.75': float(ap_75),\n        'AP_small': float(ap_small),\n        'AP_medium': float(ap_medium),\n        'AP_large': float(ap_large),\n    }\n}\n\nresults_file = 'results/baseline_results.json'\nwith open(results_file, 'w') as f:\n    json.dump(baseline_results, f, indent=2)\n\nprint(f\"\\n‚úì Results saved to: {results_file}\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"‚úì BASELINE ESTABLISHED!\")\nprint(\"=\" * 60)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T04:26:53.376954Z","iopub.execute_input":"2025-11-09T04:26:53.377226Z","iopub.status.idle":"2025-11-09T04:27:24.208615Z","shell.execute_reply.started":"2025-11-09T04:26:53.377201Z","shell.execute_reply":"2025-11-09T04:27:24.207828Z"}},"outputs":[{"name":"stdout","text":"============================================================\nEVALUATING BASELINE RESULTS\n============================================================\nloading annotations into memory...\nDone (t=0.44s)\ncreating index...\nindex created!\n\nLoading predictions...\nLoading and preparing results...\nDONE (t=1.61s)\ncreating index...\nindex created!\nComputing COCO metrics (this may take a few minutes)...\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=23.51s).\nAccumulating evaluation results...\nDONE (t=3.87s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.379\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.592\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.411\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.313\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.495\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.520\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.321\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.559\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666\n\n============================================================\nBASELINE RESULTS SUMMARY\n============================================================\n\nModel: Mask R-CNN (ResNet-50-FPN)\nFramework: Torchvision Pretrained\nDataset: COCO 2017 Validation (5000 images)\n\nBounding Box Metrics:\n  AP@IoU=0.50:0.95: 0.3789\n  AP@IoU=0.50:     0.5918\n  AP@IoU=0.75:     0.4108\n  AP_small:        0.2149\n  AP_medium:       0.4141\n  AP_large:        0.4930\n\n‚úì Results saved to: results/baseline_results.json\n\n============================================================\n‚úì BASELINE ESTABLISHED!\n============================================================\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"from torchvision.models.detection import *\nimport inspect\n\nprint(\"Available Mask R-CNN models in this session:\")\nprint(\"=\" * 60)\n\n# Get all available detection models\navailable = []\nfor name in dir():\n    if 'maskrcnn' in name.lower():\n        available.append(name)\n        print(f\"  ‚úì {name}\")\n\nif available:\n    print(f\"\\n‚úì Total available: {len(available)} models\")\nelse:\n    print(\"\\n No Mask R-CNN models found\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T04:27:24.209760Z","iopub.execute_input":"2025-11-09T04:27:24.210026Z","iopub.status.idle":"2025-11-09T04:27:24.215304Z","shell.execute_reply.started":"2025-11-09T04:27:24.209989Z","shell.execute_reply":"2025-11-09T04:27:24.214579Z"}},"outputs":[{"name":"stdout","text":"Available Mask R-CNN models in this session:\n============================================================\n  ‚úì MaskRCNN\n  ‚úì MaskRCNN_ResNet50_FPN_V2_Weights\n  ‚úì MaskRCNN_ResNet50_FPN_Weights\n  ‚úì maskrcnn_benchmark\n  ‚úì maskrcnn_path\n  ‚úì maskrcnn_resnet50_fpn\n  ‚úì maskrcnn_resnet50_fpn_v2\n\n‚úì Total available: 7 models\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import os\nimport sys\nimport torch\nimport cv2\nimport numpy as np\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\nfrom torchvision.models.detection import maskrcnn_resnet50_fpn_v2\nimport json\nimport time\n\nos.chdir('/kaggle/working/maskscoring_rcnn')\nsys.path.insert(0, '/kaggle/working/maskscoring_rcnn')\n\nprint(\"=\" * 60)\nprint(\"IMPROVEMENT C: ResNet-50 V2 (Improved Model)\")\nprint(\"=\" * 60)\n\n# COCO paths\ncoco_ann_file = '/kaggle/input/coco-2017-dataset/coco2017/annotations/instances_val2017.json'\ncoco_images_dir = '/kaggle/input/coco-2017-dataset/coco2017/val2017'\n\nprint(f\"\\n‚úì COCO annotations: {coco_ann_file}\")\nprint(f\"‚úì COCO images: {coco_images_dir}\")\n\n# Load COCO\nprint(\"\\nLoading COCO validation set...\")\ncoco_gt = COCO(coco_ann_file)\nimg_ids = sorted(coco_gt.getImgIds())\nprint(f\"‚úì Loaded {len(img_ids)} images\")\n\n# Load ResNet-50 V2 model (IMPROVED VERSION!)\nprint(\"\\nLoading Mask R-CNN with ResNet-50-FPN V2 (improved backbone)...\")\nmodel = maskrcnn_resnet50_fpn_v2(pretrained=True)\nmodel.eval()\nmodel.cuda()\nprint(\"‚úì Model loaded and moved to GPU\")\n\n# Inference\nprint(f\"\\nRunning inference on validation set...\")\nprint(\"=\" * 60)\n\npredictions = []\ntimes = []\nprocessed = 0\n\nfor idx, img_id in enumerate(img_ids):\n    img_info = coco_gt.loadImgs(img_id)[0]\n    img_path = os.path.join(coco_images_dir, img_info['file_name'])\n    \n    if not os.path.exists(img_path):\n        continue\n    \n    # Load image\n    img = cv2.imread(img_path)\n    if img is None:\n        continue\n        \n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img_tensor = torch.from_numpy(img_rgb).float().cuda() / 255.0\n    img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0)\n    \n    # Inference\n    start = time.time()\n    with torch.no_grad():\n        outputs = model([img_tensor.squeeze(0)])\n    times.append(time.time() - start)\n    \n    # Extract predictions\n    boxes = outputs[0]['boxes'].cpu().numpy()\n    scores = outputs[0]['scores'].cpu().numpy()\n    labels = outputs[0]['labels'].cpu().numpy()\n    \n    # Convert to COCO format\n    for i in range(len(boxes)):\n        x1, y1, x2, y2 = boxes[i]\n        \n        predictions.append({\n            'image_id': int(img_id),\n            'category_id': int(labels[i]),\n            'bbox': [float(x1), float(y1), float(x2-x1), float(y2-y1)],\n            'score': float(scores[i])\n        })\n    \n    processed += 1\n    \n    if (processed) % 500 == 0:\n        avg_time = np.mean(times[-500:])\n        remaining = len(img_ids) - processed\n        eta_secs = remaining * avg_time\n        print(f\"  {processed}/{len(img_ids)} - {avg_time:.3f}s/img - ETA: {eta_secs/60:.1f} mins\")\n\nprint(f\"\\n\" + \"=\" * 60)\nprint(f\"‚úì Inference complete!\")\nprint(f\"‚úì Processed: {processed} images\")\nprint(f\"‚úì Total predictions: {len(predictions)}\")\nprint(f\"‚úì Average time: {np.mean(times):.3f}s per image\")\nprint(f\"‚úì Throughput: {1/np.mean(times):.2f} FPS\")\n\n# Save predictions\nos.makedirs('results', exist_ok=True)\npred_file = 'results/resnet50v2_predictions.json'\nwith open(pred_file, 'w') as f:\n    json.dump(predictions, f)\nprint(f\"\\n‚úì Predictions saved to: {pred_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T04:27:24.216076Z","iopub.execute_input":"2025-11-09T04:27:24.216320Z","iopub.status.idle":"2025-11-09T04:38:34.387587Z","shell.execute_reply.started":"2025-11-09T04:27:24.216294Z","shell.execute_reply":"2025-11-09T04:38:34.386665Z"}},"outputs":[{"name":"stdout","text":"============================================================\nIMPROVEMENT C: ResNet-50 V2 (Improved Model)\n============================================================\n\n‚úì COCO annotations: /kaggle/input/coco-2017-dataset/coco2017/annotations/instances_val2017.json\n‚úì COCO images: /kaggle/input/coco-2017-dataset/coco2017/val2017\n\nLoading COCO validation set...\nloading annotations into memory...\nDone (t=0.44s)\ncreating index...\nindex created!\n‚úì Loaded 5000 images\n\nLoading Mask R-CNN with ResNet-50-FPN V2 (improved backbone)...\n‚úì Model loaded and moved to GPU\n\nRunning inference on validation set...\n============================================================\n  500/5000 - 0.123s/img - ETA: 9.2 mins\n  1000/5000 - 0.124s/img - ETA: 8.2 mins\n  1500/5000 - 0.124s/img - ETA: 7.2 mins\n  2000/5000 - 0.123s/img - ETA: 6.2 mins\n  2500/5000 - 0.123s/img - ETA: 5.1 mins\n  3000/5000 - 0.124s/img - ETA: 4.1 mins\n  3500/5000 - 0.124s/img - ETA: 3.1 mins\n  4000/5000 - 0.124s/img - ETA: 2.1 mins\n  4500/5000 - 0.126s/img - ETA: 1.0 mins\n  5000/5000 - 0.124s/img - ETA: 0.0 mins\n\n============================================================\n‚úì Inference complete!\n‚úì Processed: 5000 images\n‚úì Total predictions: 160837\n‚úì Average time: 0.124s per image\n‚úì Throughput: 8.07 FPS\n\n‚úì Predictions saved to: results/resnet50v2_predictions.json\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import os\nimport json\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\n\nos.chdir('/kaggle/working/maskscoring_rcnn')\n\nprint(\"=\" * 60)\nprint(\"EVALUATING RESNET-50 V2 RESULTS\")\nprint(\"=\" * 60)\n\n# Load baseline results from file\nbaseline_file = 'results/baseline_results.json'\nif os.path.exists(baseline_file):\n    with open(baseline_file, 'r') as f:\n        baseline_data = json.load(f)\n    \n    baseline_ap = baseline_data['metrics']['AP@0.50:0.95']\n    baseline_ap_50 = baseline_data['metrics']['AP@0.50']\n    baseline_ap_75 = baseline_data['metrics']['AP@0.75']\n    baseline_ap_small = baseline_data['metrics']['AP_small']\n    baseline_ap_medium = baseline_data['metrics']['AP_medium']\n    baseline_ap_large = baseline_data['metrics']['AP_large']\n    \n    print(f\"‚úì Loaded baseline from: {baseline_file}\")\n    print(f\"  Baseline AP: {baseline_ap*100:.2f}%\")\nelse:\n    print(f\"‚úó Baseline file not found: {baseline_file}\")\n    print(\"Cannot proceed without baseline\")\n    exit()\n\n# Load ground truth\ncoco_ann_file = '/kaggle/input/coco-2017-dataset/coco2017/annotations/instances_val2017.json'\ncoco_gt = COCO(coco_ann_file)\n\n# Load predictions\nprint(\"\\nLoading predictions...\")\npred_file = 'results/resnet50v2_predictions.json'\ncoco_dt = coco_gt.loadRes(pred_file)\n\n# Evaluate\nprint(\"Computing COCO metrics (this may take a few minutes)...\")\ncoco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\ncoco_eval.evaluate()\ncoco_eval.accumulate()\ncoco_eval.summarize()\n\n# Extract results\nap_50_95 = coco_eval.stats[0]\nap_50 = coco_eval.stats[1]\nap_75 = coco_eval.stats[2]\nap_small = coco_eval.stats[3]\nap_medium = coco_eval.stats[4]\nap_large = coco_eval.stats[5]\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"RESNET-50 V2 vs BASELINE COMPARISON\")\nprint(\"=\" * 60)\n\nprint(f\"\\n{'Metric':<20} {'ResNet-50 V2':<15} {'Baseline':<15} {'Change':<10}\")\nprint(\"-\" * 70)\nprint(f\"{'AP@0.50:0.95':<20} {ap_50_95*100:>6.2f}% {baseline_ap*100:>14.2f}% {(ap_50_95*100-baseline_ap*100):>9.2f}%\")\nprint(f\"{'AP@0.50':<20} {ap_50*100:>6.2f}% {baseline_ap_50*100:>14.2f}% {(ap_50*100-baseline_ap_50*100):>9.2f}%\")\nprint(f\"{'AP@0.75':<20} {ap_75*100:>6.2f}% {baseline_ap_75*100:>14.2f}% {(ap_75*100-baseline_ap_75*100):>9.2f}%\")\nprint(f\"{'AP_small':<20} {ap_small*100:>6.2f}% {baseline_ap_small*100:>14.2f}% {(ap_small*100-baseline_ap_small*100):>9.2f}%\")\nprint(f\"{'AP_medium':<20} {ap_medium*100:>6.2f}% {baseline_ap_medium*100:>14.2f}% {(ap_medium*100-baseline_ap_medium*100):>9.2f}%\")\nprint(f\"{'AP_large':<20} {ap_large*100:>6.2f}% {baseline_ap_large*100:>14.2f}% {(ap_large*100-baseline_ap_large*100):>9.2f}%\")\n\n# Save results\nresnet50v2_results = {\n    'improvement': 'ResNet-50 V2 (Improved Backbone)',\n    'model': 'Mask R-CNN (ResNet-50-FPN V2)',\n    'framework': 'Torchvision',\n    'dataset': 'COCO 2017 Validation',\n    'num_images': len(coco_gt.getImgIds()),\n    'num_predictions': len(json.load(open(pred_file))),\n    'inference_time': {\n        'avg_per_image': 0.124,\n        'throughput_fps': 8.06\n    },\n    'metrics': {\n        'AP@0.50:0.95': float(ap_50_95),\n        'AP@0.50': float(ap_50),\n        'AP@0.75': float(ap_75),\n        'AP_small': float(ap_small),\n        'AP_medium': float(ap_medium),\n        'AP_large': float(ap_large),\n    },\n    'comparison_with_baseline': {\n        'baseline_model': baseline_data.get('model', 'Mask R-CNN (ResNet-50-FPN)'),\n        'baseline_ap': float(baseline_ap),\n        'new_ap': float(ap_50_95),\n        'improvement_absolute': float(ap_50_95 - baseline_ap),\n        'improvement_relative': float((ap_50_95 - baseline_ap) / baseline_ap * 100)\n    }\n}\n\nresults_file = 'results/resnet50v2_results.json'\nwith open(results_file, 'w') as f:\n    json.dump(resnet50v2_results, f, indent=2)\n\nprint(f\"\\n‚úì Results saved to: {results_file}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"IMPROVEMENT C - SUMMARY\")\nprint(\"=\" * 60)\nprint(f\"Baseline (ResNet-50 V1):  {baseline_ap*100:.2f}% AP\")\nprint(f\"ResNet-50 V2:             {ap_50_95*100:.2f}% AP\")\nprint(f\"Absolute improvement:     {(ap_50_95-baseline_ap)*100:+.2f}%\")\nprint(f\"Relative improvement:     {((ap_50_95-baseline_ap)/baseline_ap)*100:+.2f}%\")\n\nif ap_50_95 > baseline_ap:\n    print(\"\\n IMPROVEMENT SUCCESSFUL!\")\nelse:\n    print(\"\\n No improvement observed\")\n\nprint(\"=\" * 60)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T04:38:34.388796Z","iopub.execute_input":"2025-11-09T04:38:34.389125Z","iopub.status.idle":"2025-11-09T04:39:04.679254Z","shell.execute_reply.started":"2025-11-09T04:38:34.389095Z","shell.execute_reply":"2025-11-09T04:39:04.678627Z"}},"outputs":[{"name":"stdout","text":"============================================================\nEVALUATING RESNET-50 V2 RESULTS\n============================================================\n‚úì Loaded baseline from: results/baseline_results.json\n  Baseline AP: 37.89%\nloading annotations into memory...\nDone (t=0.44s)\ncreating index...\nindex created!\n\nLoading predictions...\nLoading and preparing results...\nDONE (t=0.66s)\ncreating index...\nindex created!\nComputing COCO metrics (this may take a few minutes)...\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=23.99s).\nAccumulating evaluation results...\nDONE (t=3.93s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.679\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.519\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.309\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.512\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.611\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.367\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.589\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.618\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.445\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.649\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764\n\n============================================================\nRESNET-50 V2 vs BASELINE COMPARISON\n============================================================\n\nMetric               ResNet-50 V2    Baseline        Change    \n----------------------------------------------------------------------\nAP@0.50:0.95          47.39%          37.89%      9.50%\nAP@0.50               67.90%          59.18%      8.72%\nAP@0.75               51.86%          41.08%     10.78%\nAP_small              30.89%          21.49%      9.40%\nAP_medium             51.17%          41.41%      9.75%\nAP_large              61.09%          49.30%     11.79%\n\n‚úì Results saved to: results/resnet50v2_results.json\n\n============================================================\nIMPROVEMENT C - SUMMARY\n============================================================\nBaseline (ResNet-50 V1):  37.89% AP\nResNet-50 V2:             47.39% AP\nAbsolute improvement:     +9.50%\nRelative improvement:     +25.08%\n\n IMPROVEMENT SUCCESSFUL!\n============================================================\n","output_type":"stream"}],"execution_count":24}]}